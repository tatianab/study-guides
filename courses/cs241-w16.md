# CS 241 - Advanced Compiler Construction
Professor : Michael Franz  
Quarter   : Winter 2016  

## Scanning and Parsing

## Control Flow Graphs

**Nodes and edges**  
A CFG is a collection of nodes and edges.  
Nodes are "basic blocks" - sequences of instructions that must be executed
together, or not at all. Can be seen as a "unit of control flow".
We can only enter a basic block at the top, and exit at the bottom.

Edges are branches, which can be explicit or implicit.
By convention, right edges are explicit branches and left edges are implict
branches (fall-through).

**Local vs. Global Optimizations**  
Local optimizations occur within a basic block, global optimizations occur
between basic blocks

### Dominators

Definition. A basic block D **dominates** another block A (written D dom A) if
every path from the start of the program to A goes through D. (This 
relationship can be built during parsing).

A **dominator tree** shows dominator relationships. (Ancestors dominate 
descendants).

Definition. A basic block D **strictly dominates** another block A (written
D sdom A) if D dominates A and D is not equal to A.

Definition. A basic block P **post-dominates** another block A (written
D postdom A) if every path from A to the end of the program goes through P.

So the range of Dominator through Postdominator is the range of places we can
put instructions and still do that computation.

### Reducibility

A CFG is well-formed or **reducible** if it can be partitioned into two
disjoint edge sets: the forward edge set (which forms a DAG), and a back edge
set in which every head dominates its tails.

Counter example:
```
[B1] --> [B2] --> [B3]  
     --------------> 
     	  <------
```
Which is the head: B2 or B3?
Most optimizing compilers won't deal wih this.
- This is one way to obfuscate code.
- "Good" languages don't allow irreducible flow-graphs.

Solution to irreducibility: **"node splitting"**. Problem: potential code
explosion. B2 could be arbitrarily large; code obfuscators take advantage of 
this.

```
[B1] --> [B2]     [B3]    [B3']
     -----------> 
     	  <------
     	  ----------------->
     	  <-----------------
```

## Static Single Assignment
SSA proposed in 1989 - "quantum leap".  
"Static" - look at programs statically, ignore loop iterations.  
Idea: translate a program into an intermediate representation in which
every variable is defined only once. If a variable is re-defined, SSA gives the
new version a new name.  

Motivation:
```
i : op x y
...
j : op x y
```
How do we know if it is OK to eliminate line j? OK iff:  
1. Neither x nor y changed in between.
2. No way to reach j without passing through i.

SSA immediately gets rid of problem 1. Problem 2 can be solved with dominator
relationships (i.e., if i dominates j then we know it's OK to eliminate j).

### Phi functions
Issue: what if two different versions of the same variable flow together?
Example  
```
if i < 0 then
	min = i
else
	min = j
print min; # Which version of min do I print?
```
Solution: phi functions!
Add `phi(min1, min2)` before print.

`phi(x,y)` = x if we came from left, y if we came from right.
Phi is a hint to the register allocator to put x and y into the same
register if possible.

We assume that phi is an opcode until register allocation.

### "Pure SSA"
- No move instructions.
- No variables (only unique values).

### SSA generation
TODO

### Quadruples and Triples

**Quadruples**  
3-argument instructions.
Example:
```
a := b * c + d * 7 
	t1 = b * c     ==> mul t1 b c
	t2 = d * 7     ==> muli t2 d #7
	a  = t1 + t2   ==> add a t1 t2
```
**Triples**  
Every instruction generates a value.
Example:
```
a := b * c + d * 7 
	1 : mul b c
	2 : muli d #7
	3 : add (1) (2) # (X) is result of X. Actually a pointer to X.
	4 : store a (3)
```
Problem: ternary operations (array access). We can handle this with two
consecutive, inseparable operations.

## Optimizations
### Common Subexpression Elimination
Idea: delete redundant instructions.
Scenario:  
```
i : op x y
...
j : op x y

i dom j
```
Eliminate j, and install a "forwarding pointer" to i wherever j is used.

### Copy Propagation
Idea: delete unecessary move instructions.
Scenario:  
```
move a --> b
```
Delete b, install a forwarding pointer to a wherever b is used.

### Dead code elimination
Idea: delete any instructions whose results are never used.

## Register Allocation
**Live ranges**  
Where does a value start / stop living? i.e., when is its first and last use?

**Register pressure**  
Spilling - putting things in memory that you don't have room for.  
SSA - assume unlimited register set, first N are "fast." Compact everything
so that most things can end up at least in the cache.  
So we have: real registers, and "virtual registers" with labels > N.  
Reserve two real registers as proxies for all of the virtual registers (to
store values to be computed on).

### Interference graph
Nodes - SSA values.  
Edges - between two values that co-exist at any point in time.

**Building interference graph**
(Dead code elimination can happen at the same time)  
```
Go from the end of the program to the beginning.
Operands of instructions must be alive.
For each instr i : op j k
	1. live = live - {i}
	2. for all x in live: add edge i <--> x
	3. live = live + {j, k}
```
If/while constructs?

### Linear scan

### Graph coloring
Color a graph with k colors such that no two nodes get the same color.
- This is NP-Hard. We need a heuristic.
- Takes up ~%60 of runtime of compiler.

**Simple algorithm for graph coloring:**  
```
Color(graph): # Given n registers.
	x = arbitrary node with fewer than n neighbors.
	(If no such x exists, take x with lowest cost. This will go into main
	 memory.)
	Remove x and its edges from graph.
	Color(remaining graph)
	Add x and its neighbors back.
	Choose color for x that is different from all neighbors.
	(If no such color exists, allocate storage in memory.)
```
We need a cost function that somehow indicates how many times this value is
used. Higher cost --> more accesses.

Ex. cost function: # of uses, scaled by loop nesting depth.

**SAT Solver for graph coloring**  
SAT solver - constraint solver for propositional satisfiability. 
Given a formula of 0,1, AND, OR and NOT, find a satisfying assignment or
prove that none exists.   

**Example : 4-colorability with SAT solver**  
```
Variables are colors: c0 c1 c2 c3.  
Encode the colors as 2-bit values: 00, 01, 10, or 11.  
If i and j are adjacent in the interference graph, then they have different
color, expressed as:
	NOT ((c_i0 == c_j0) AND (c_i1 == c_j1))
c_i0 == c_j0 is expressed as:
	(c_i0 AND c_j0) OR (NOT c_i0 AND NOT c_j0).
Connect adjacency info with AND, then solve.
```
This results in enormous formulas, and is currently impractical.

## Instruction Scheduling

## Code generation
**Variable Storage**  

| Memory  |                       |
|:--------|:---------------------:|
| 0       | --- Begin Code  ---   |
|         | ... 		          |
|         | --- End Code    ---   | 
|         | --- End Stack   ---   | 
|         | ...                   |  
|         | --- Begin Stack ---   |  
|         | --- End Globals ---   | 
|         | ...                   |   
| MAX     | --- Globals     ---   |  

**DLX Reserved Registers**    
R0  - always 0.  
R28 - FP.  
R29 - SP.  
R30 - Globals.  
R31 - Return address.  

Variables have contiguous addresses (possibly padded to ensure no item spans
more than one line).

### Function handling
**Caller saved vs. callee saved**  
Who keeps track of the state of registers when a function call is made?

**Function calling**  

1. Save return address.
2. Save old frame pointer.
3. Set FP = SP.
4. Reserve space for local variables.

**Activation Record:**  

|				  |           |
| :-------------- | :-------: |
| Parameters      |           |
| Return Address  | -- FP     |
| Old FP          |           |
| Locals          | -- SP     |


**Parameter passing**  
Can be via registers or stack.  
In stack, stored above return address.

**Function results**  
Can be via registers or stack. (Probably registers).  

Pre-SSA : register - variable correspondence.   
SSA : register - value correspondence.

## Speculative Processor Features

## Software Pipelining

## Cache-concious Data Structures

## Object-oriented Features
### Single inheritance
### Multiple inheritance

## Security Issues
### Return-oriented programming
### Control flow integrity
