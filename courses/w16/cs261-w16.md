# CS 261 - Data Structures
Professor : David Eppstein  
Quarter   : Winter 2016  

## Potential method of amortized analysis
```
Amortized time of an op = 
		= actual time + C(phi(after op) - phi(before op))
```
Intution: Bank account of saved time.
Phi increases: amortized > actual, saving time for later.
Phi decreases: amortized < actual, spending saved time.

Theorem: For any function phi and constant C, where phi >= 0, C>0, and Phi(pre-init) = 0, and for any sequence of operations:
	`Sum of amortized time >= Sum of actual time`.

#### Example : Dynamic Arrays
Resize a static array by a growth factor g when array gets too big.

Operations: 
- Init O(1)
- Length O(1)
- Lookup/Change ith value O(1)
- Shrink O(1)
- Grow O(1) amortized.

Amortized analysis: `Phi = (g * length) - capacity.`

## Hash tables

### Dictionary Problem
Collection of key value pairs.
Operations: search, add, remove.

### Hash table structure
(Common dictionary solution).
Map keys to indices in an array using a hash function.

### Hash collision handling
**Hash chaining**
Store multiple key-value pairs per array cell.
O(1) when load factor (# keys / # cells) is O(1).
**Linear probing**
Store one key-value pair per array cell (If cell is full, try the next) -- O(1).

### Cuckoo hashing
Use two hash functions.
Hash key with current hash function. If full, evict the current key and find it a new place with other hash function.
(If infinite loop, rebuild with new hash).
O(1) expected, slowest O(log n).

### Hash functions
**Cryptographic hash functions**
Keys --> Big numeric range.
Hard to find collisions, hard to distinguish from random. 
Drawback: Slow.
**k-independent hashing**
For every k-tuple of distinct keys and every l-tuple C of 
	  (not necessarily distinct) cells:
	  Pr[ h(k1) = c AND h(k2) = c2 AND ... AND h(kl)] = cl] = 1/(N^l)
	  (where N is number of cells in hash table).
**Tabulation hashing**
Divide key into blocks of r bits.
Fill w/r tables of 2^r random #'s
		h(x) = T0[x0] XOR T1[x1] XOR ... XOR Tk[xk]
This is 3-indep, but not 4-indep.

## Bloom filters & Streaming
### Bloom filter
	- Inexact representation of a set with the possibility of false positives.
	- Smaller space utilization that hash table or bit array.
	- O(n) bits for any constant false positive rate.
	- Use k hash functions to map each set element to k different cells.
	- Add to set by setting all hashed bits, check membership by checking bits.
	- Pr[ false positive ] = (1/2)^k for k = (ln 2) * (m / n)
	  (n is # of insertions, m is number of bits in array).
### Invertible bloom filters
Symmetric Difference:
`X Triangle Y = { elems in one but not other } = (X union Y) - (X intersect Y)`
Invertible bloom fliter:

- Bloom filter where each cell stores: # elems, Sum of elems, checksum.
- To invert: Find elem with # elems = 1 and checksum matches, output its
  elements and remove it from all cells. Repeat.
- Either we find an empty IBF or fail.
- Find diff by subtracting two IBFs.

### MinHash
Jaccard similarity: `| X intersect Y | / | X union Y|`  
Represent set by the k smallest hashes of its elements.

### Frequent item detection
At any time, report k "best" id + # times they appear (within n/k)
Guarantee that if any id x forms >= n/k of the stream (where n is current
stream length) then we report x.  
```
Store k cells with x_i (the id) and n_i (the number of times seen).
If we see id y: 
	If y in the set, increment corresponding n.
	Otherwise if there is an ni = 0, set xi = y, ni = 1.
	Otherwise, decrement everyone's n.
```
## Heaps

### Priority queues
Maintain set of elems with numerical priorities.  
Find and remove the element with the highest priority.

### Binary heaps
Heap property - for all 0 < x < n: priority(parent of x) <= priority(x).
Operations: init O(n), all else O(log n): find/remove min, insert, 
increase/decrease priority.
"Fix heap" by percolating elements up or down.

### k-ary heaps	
Every node has up to k children.
Operations:
- Find and remove O(k * (log n)/(log k))
- Decrease priority O(log n / log k)
- Every node has up to k children.
- Find and remove O(k * (log n)/(log k))
- Decrease priority O(log n / log k)

### Fibonacci heaps

## Binary Search Trees
### Random BSTs
### AVL trees
Height balanced. Left and right subtrees differ by at most 1.
### Rank-balanced trees
### Splay trees
#### Static optimality
For any sequence of operations starting from an empty tree:  
For any fixed binary search tree T on same elements:
	`Time-splay(Sequence) = O(Time-T(Sequence))`

#### Dynamic optimality conjecture
Static optimality with non-fixed T. (Conjecture)

### Competitive analysis
A method for comparing online algorithms to their offline counterparts.
Basically answers the questions: how much worse am I than the optimal?

**Competitive ratio**

## Tries and Suffix Trees
Problem (Abstraction of Google search problem)  
input data: string of symbols  
preprocess data structure with low memory that can find queries / substrings
quickly.

Simpler version  
data : collection of (short) strings
query : one string
answer : does the query match any input string?

**Trie**  
Given any set of strings:
- prefix : substring formed by deleting characters from the end.
- parent(string) : delete last char of string
- root : empty string
Defines a tree on any collection of strings.

How to store?
- object for every node
- array or hash table of children, by character
- add end marker to signal end of actual string
- nodes don't store prefixes (edges store chars).

Total size: O(sum of string length).

**Compressed Tries**  
Take normal trie, and remove non-root nodes with only one child.
- Replace edge labels (can now be strings rather than chars).

Size : O(# strings).

**Suffix Trees**  
Compressed trie of all suffixes of a certain string.
Space O(length of string).

## Range searching
### Dynamic prefix sums
### Augmented BSTs
### Fractional cascading
### Range minima
### Cartesian trees
### Lowest common ancestors
### Level ancestors

## Van Emde Boas Trees
Problem: priority queue of integer data with small (B-bit binary integer)
keys and priorities.
Time O(logB) --> O(log log n) for n numbers.

VEB tree for i-bit #'s has:
	- min and max of its numbers
	- for remaining values:
		- VEB tree for i/2 bit high-order halfwords.
		- hash table : keys (high half words) --> (map to) values (VEB tree
		  of corresponding low half words)

Queries:
- find min (return root.min)
- find successor(x)
- insert(x)

## Persistence

## Union-find